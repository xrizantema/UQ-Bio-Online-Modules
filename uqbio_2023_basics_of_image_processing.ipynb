{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xrizantema/UQ-Bio-Online-Modules/blob/main/uqbio_2023_basics_of_image_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrDdrqdrefmB"
      },
      "source": [
        "\n",
        "\n",
        "<html>\n",
        "    <summary></summary>\n",
        "    <p float=\"left\">\n",
        "        <img align=\"left\" src=\"https://raw.githubusercontent.com/Will-Raymond/uqbio2023/master/files/uqiobio2023_logo_color_large_w_padding.png\"  width=\"340\" height=\"300\"/>\n",
        "         <div> <p></p> </div>\n",
        "         <div style=\"font-size: 200px; width: 200px;\"> \n",
        "              <h1>\n",
        "               <left>Python Tutorial Basics of Image Processing </left>\n",
        "              </h1>\n",
        "              <p><left>============================================================================</left> </p>\n",
        "              <h2><left>UQ-Bio Summer School 2023 </left></h2>\n",
        "              <pre>Instructor: Luis Aguilera\n",
        "Authors: Will Raymond, Zach Fox, Dr. Luis Aguilera\n",
        "Contact Info: luis.aguilera@colostate.edu\n",
        "</pre>\n",
        "         </div>\n",
        "    </p>\n",
        "\n",
        "</html>\n",
        "\n",
        "\n",
        "\n",
        "<details>\n",
        "  <summary>Copyright info</summary>\n",
        "\n",
        "```\n",
        "Copyright 2023 Brian Munsky\n",
        "\n",
        "Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n",
        "\n",
        "1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\n",
        "\n",
        "2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\n",
        "\n",
        "3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n",
        "\n",
        "THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
        "```\n",
        "<details>\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Abstract \n",
        "\n",
        "In this notebook, we will talk about single-cell segmentation and spot detection using Python. By now, we have covered basic image manipulation [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1Jm2V58QRtjvJ7kx4WQfUGoGkBBKF7JVB?usp=sharing). Here, our goal is introduce the basics of single-cell segmentation and particle detection. \n",
        "\n",
        "## List of objectives\n",
        "\n",
        "1. Understand and explain the more common methods used to segment cells from microscope images.\n",
        "2. Understand and explain what a ***segmentation mask is***.\n",
        "3. Understand and explain segmentation methods based on **threshold selection**.\n",
        "4. Perform single-cell segmentation using **machine learning** based methods. \n",
        "5. Understand the basics of **particle detection**."
      ],
      "metadata": {
        "id": "FiskOfmuh3kB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src= https://github.com/MunskyGroup/uqbio2022/raw/master/files/files_image_processing/module_1_3/images/Slide2.png alt=\"drawing\" width=\"1200\"/>"
      ],
      "metadata": {
        "id": "c1GXNcnnA35h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cell segmenation and spot detection (Summary): \n",
        "\n",
        "1.   Thresholding\n",
        "2.   Binarization\n",
        "3.   Labeling\n",
        "\n"
      ],
      "metadata": {
        "id": "Of7qHN_AcckN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src= https://github.com/MunskyGroup/uqbio2022/raw/master/files/files_image_processing/module_1_2/images/Slide2.png alt=\"drawing\" width=\"1200\"/>"
      ],
      "metadata": {
        "id": "myDW1oXaI6eQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src= https://github.com/MunskyGroup/uqbio2022/raw/master/files/files_image_processing/module_1_2/images/Slide3.png alt=\"drawing\" width=\"1200\"/>"
      ],
      "metadata": {
        "id": "aLR44_1zI_EI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src= https://github.com/MunskyGroup/uqbio2022/raw/master/files/files_image_processing/module_1_2/images/Slide4.png alt=\"drawing\" width=\"1200\"/>"
      ],
      "metadata": {
        "id": "7NI7-7PeJGFX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Do it by hand\n",
        "Using software such as [ImageJ/FIJI](https://imagej.nih.gov/ij/), [Napari](https://napari.org) or even something like Microsoft Paint, one can manually outline cells. This is cumbersome and impractical for processing thousands of cells over time. "
      ],
      "metadata": {
        "id": "rD8MWhHDPngt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src= https://github.com/MunskyGroup/uqbio2022/raw/master/files/files_image_processing/module_1_2/images/Slide5.png alt=\"drawing\" width=\"1200\"/>"
      ],
      "metadata": {
        "id": "DTzoxtM5JQrU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Check this tool ([makesense](https://www.makesense.ai)) to create your own masks.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bwOmK0TNuMNh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can find some images in the following [link](https://www.dropbox.com/s/d9my4cp2j3ven04/test_data_uqbio2022.zip?dl=0)"
      ],
      "metadata": {
        "id": "uPtmi1A99Bj-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yV1XbVUemLL"
      },
      "source": [
        "# Getting started with segmentation using thresholding"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Watershed Methods\n",
        "The scikit-image library has an excellent tutorial on [watershed methods](https://scikit-image.org/docs/dev/auto_examples/segmentation/plot_watershed.html). Popular tools that apply such methods to single cells are:\n",
        "* [CellStar](http://cellstar-algorithm.org) (Matlab, Python, CellProfiler PlugIn)\n",
        "* [FogBank](https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-014-0431-x#additional-information) (Matlab)"
      ],
      "metadata": {
        "id": "mvSjR9G263Lu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src= https://github.com/MunskyGroup/uqbio2022/raw/master/files/files_image_processing/module_1_2/images/Slide6.png alt=\"drawing\" width=\"1200\"/>"
      ],
      "metadata": {
        "id": "VkxfpjV7JLk4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4sEg4oNqF7m"
      },
      "source": [
        "%%capture\n",
        "# Loading libraries\n",
        "import random                        # Library to generate random numbers\n",
        "import skimage                       # Library for image manipulation\n",
        "import numpy as np                   # Library for array manipulation\n",
        "import urllib.request                # Library to download data\n",
        "import matplotlib.pyplot as plt      # Library used for plotting\n",
        "from skimage import io               # Module from skimage\n",
        "from skimage.io import imread        # Module from skimage to read images as numpy arrays\n",
        "from skimage.filters import gaussian # Module working with a gaussian filter\n",
        "import pathlib                              # Library to work with file paths\n",
        "import os\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title List of Participants\n",
        "participants = ['Kaitlyn', 'Kwabena', 'Natalia', 'Alexandra', 'Clincy', 'Jorge Luis', 'Daniel', 'Logan', 'João Pedro', 'Luciano', 'Lucy', 'Alec', 'Emma', 'Thomas', 'Rosaline', 'Zabiba', 'Jack', 'Joshua', 'Jason', 'Rachel', 'Michael', 'Miranda', 'Aishwarya', 'Andrea', 'Molly', 'Miguel', 'Morris', 'Suraj', 'Myles', 'Adam', 'Sayeh', 'Amir', 'Yukai']\n",
        "#random.choice(participants)"
      ],
      "metadata": {
        "id": "ivulU3SaxjPS",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aomp36oZtG76"
      },
      "source": [
        "Let's get started by downloading a sample image of a cell and plotting it using `matplotlib`:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLyKJMqKqQ4k"
      },
      "source": [
        "# Downloading a test image\n",
        "urls = ['https://ndownloader.figshare.com/files/26751209']\n",
        "print('Downloading file...')\n",
        "figName = './image_cell.tif'\n",
        "urllib.request.urlretrieve(urls[0], figName)\n",
        "# Loading figure to the notebook\n",
        "images = imread(figName) \n",
        "print('File is downloaded and accessible in: ... /contents/image_cell.tif ')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Explain        figName = './image_cell.tif'   what is our cwd?    #import os #os.getcwd()\n",
        "random.choice(participants)"
      ],
      "metadata": {
        "id": "cDkStCTuxpND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIQDfN7SseSF"
      },
      "source": [
        "# Printing the shape of the image\n",
        "print('Original image shape: ' , images.shape)  # [T,Y,X,C]\n",
        "# Selecting a frame and a color channel\n",
        "img = images[0,:,:,0]\n",
        "print('Single image shape: ' , img.shape)  # [Y,X]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Difference  between images and img?\n",
        "random.choice(participants)"
      ],
      "metadata": {
        "id": "kXYlGZuLyBDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Plotting the image as the 3d dimension figure.\n",
        "space= np.arange(0, img.shape[0], 1)\n",
        "xx, yy = np.meshgrid(space,space)\n",
        "fig = plt.figure(figsize=(15,7))\n",
        "# Set up the axes for the first plot\n",
        "ax = fig.add_subplot(1, 2, 1)\n",
        "ax.imshow(img,cmap='Spectral') # Reds_r\n",
        "# Set up the axes for the second plot\n",
        "ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n",
        "ax2.plot_surface(xx, yy , img,  rstride=20, cstride=20, shade=False, cmap='Spectral')\n",
        "ax2.view_init(20, 45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hUdKmu8sK-WO",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4kyOnGit7TY"
      },
      "source": [
        "Recall when we plotted the histogram of the intensity pixels to get a sense of the distribution of pixel intensities throughout the image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIdRU5m7t5qI"
      },
      "source": [
        "# Plotting the intensity distribution\n",
        "f, ax = plt.subplots()\n",
        "_ = ax.hist(img.flatten(),color='orangered',bins=35)  # .ravel()\n",
        "ax.set_xlabel('pixel')\n",
        "ax.set_ylabel('# of pixels')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#_ = ax.hist(img.flatten(),color='orangered',bins=35)  # .ravel()\n",
        "random.choice(participants)   "
      ],
      "metadata": {
        "id": "Kl7nsVhZypXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Segmentaton based on threshold selection"
      ],
      "metadata": {
        "id": "YryL4pa6WbwY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1z48XCyufes"
      },
      "source": [
        "Based on this image, we can guess a threshold of pixel intensities that are \"cells\" vs \"not cells\". What do you think would make a good threshold?\n",
        "\n",
        "_Modify the cell below and try different thresholds_\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZNHIVJyuUu3"
      },
      "source": [
        "# Thresholding the image\n",
        "threshold = 700   # Please play  with this threshold\n",
        "mask_image = np.zeros(img.shape)\n",
        "mask_image[img>threshold] = 255\n",
        "f,ax = plt.subplots()\n",
        "ax.imshow(mask_image, cmap='Greys')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grjDaogdv3oK"
      },
      "source": [
        "This mask image is useful, especially considering we simply took all of the pixels with a value bigger than `threshold`. \n",
        "\n",
        "However, we know that the outside ought to be more smooth. Let's try applying a Gaussian filter to smooth out the mask image:\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing library with the watershed algorithm. \n",
        "from skimage.morphology import binary_dilation\n",
        "from skimage.segmentation import watershed"
      ],
      "metadata": {
        "id": "Cm43XgFcX_jG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzF6Y7hFJ0RY"
      },
      "source": [
        "# Applying a gaussian filter to the image\n",
        "new_mask = gaussian(mask_image, sigma=5) \n",
        "f,ax = plt.subplots()\n",
        "ax.imshow(new_mask, cmap='Greys')\n",
        "plt.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing a library to find contours in the image\n",
        "from skimage import measure"
      ],
      "metadata": {
        "id": "X1e-1l96YSHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umZNGAcpnyBc"
      },
      "source": [
        "# Plotting all contours detected in the filtered image\n",
        "f,ax = plt.subplots()\n",
        "contours = measure.find_contours(new_mask, level=125 ) # level is half of 255 (ish). What happens if we change it?\n",
        "ax.imshow(new_mask, cmap='Greys')\n",
        "for contour in contours:\n",
        "  ax.plot(contour[:,1],contour[:,0],color='r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#help(measure.find_contours)\n",
        "random.choice(participants)   "
      ],
      "metadata": {
        "id": "LsPgscPyTV2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nbFhRs0O0X2"
      },
      "source": [
        "# Plotting the countour on top of the original image\n",
        "img = images[0,:,:,0]\n",
        "f,ax = plt.subplots()\n",
        "ax.imshow(img, cmap='Greys')\n",
        "for contour in contours:\n",
        "  ax.plot(contour[:,1],contour[:,0],'r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYTvmKbHxNkO"
      },
      "source": [
        "So far so good. By setting `threshold=700` we were able to find the \"main\" cell in the image. But what happens when we want to get all three? Let's start by lowering the threshold to  300 and running the code. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrfLV6F1ybeQ"
      },
      "source": [
        "threshold = 300"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Thresholding with a lower value\n",
        "mask_image = np.zeros(img.shape)\n",
        "mask_image[img>threshold] = 255\n",
        "new_mask = gaussian(mask_image, sigma=4) # applaying the gaussian filter\n",
        "contours = measure.find_contours(new_mask, level=125, fully_connected='high') # Finding the contours in the image\n",
        "img = images[0,:,:,0]\n",
        "\n",
        "#  Plotting the  contour detected on top of the original image\n",
        "f,ax = plt.subplots()\n",
        "ax.imshow(img, cmap='Spectral')\n",
        "contours_connected = np.vstack((contours))\n",
        "print(contours_connected.shape)\n",
        "for contour in contours:\n",
        "  ax.plot(contour[:,1],contour[:,0],'-b',lw=8)\n",
        "\n",
        "# Connecting the last and first  elements in the array (contours) to get a fully connected shape\n",
        "contours_connected = np.vstack((contours_connected[-1,:],contours_connected))\n",
        "print(contours_connected.shape)\n",
        "\n",
        "# Plotting\n",
        "ax.plot(contours_connected[:,1],contours_connected[:,0],'y',lw=3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xW0vt18ZYxu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAAHGObey5df"
      },
      "source": [
        "_it looks like a crab_ !\n",
        "\n",
        "\n",
        "In the cell below, we will try to take the connected image below and use a [watershed algorithm](https://en.wikipedia.org/wiki/Watershed_(image_processing) to break it into 3 distinct cells. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing a library to convert contours into shapes.\n",
        "from skimage.draw import polygon"
      ],
      "metadata": {
        "id": "2eRhQg28bWbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfxyAEnNzCJM"
      },
      "source": [
        "# make a new mask from the contours array\n",
        "watershed_starting_mask = np.zeros(img.shape).astype(int)                    # Prealocating an array with zeros. Notice the datatype.\n",
        "rr, cc = polygon(contours_connected[:,0], contours_connected[:,1])           # Returns the coordinates inside the contour\n",
        "watershed_starting_mask[rr,cc] = 1                                           # Replacing all values inside the contour with ones.\n",
        "\n",
        "# Plotting the mask \n",
        "f,ax = plt.subplots()\n",
        "ax.imshow(watershed_starting_mask, cmap='Greys_r')\n",
        "plt.show()\n",
        "\n",
        "# Printing the minimum and maximum values in the image\n",
        "print('min value in mask: ', np.min(watershed_starting_mask) )\n",
        "print('max value in mask: ', np.max(watershed_starting_mask) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#watershed_starting_mask = np.zeros(img.shape).astype(int)                    # Prealocating an array with zeros. Notice the datatype.\n",
        "random.choice(participants)"
      ],
      "metadata": {
        "id": "1TqT2b950UT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing libraries with the watershed algorithm and local maximum detection\n",
        "from scipy import ndimage as ndi              # Distance Transform\n",
        "from skimage.feature import peak_local_max    # Local maxima in a matrix\n",
        "from skimage.segmentation import watershed    # Watershed algorithm"
      ],
      "metadata": {
        "id": "GzGw_zsccpmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find more information about the specific method use\n",
        "\n",
        "```\n",
        "help(watershed)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "JAaH0cmFfjJc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Distance transform"
      ],
      "metadata": {
        "id": "Q_wgirknvBzR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\"The distance transform computes the distance between each pixel and the nearest zero/nonzero pixel.\" An example with code implementation is accessible in this [link](https://www.youtube.com/watch?v=oxWfLTQoC5A).\n",
        "\n",
        "For more infromation about the distance transform check this [link](https://homepages.inf.ed.ac.uk/rbf/HIPR2/distance.htm)\n",
        "\n",
        "<img src= https://homepages.inf.ed.ac.uk/rbf/HIPR2/figs/distance.gif alt=\"drawing\" width=\"600\"/>\n",
        "\n"
      ],
      "metadata": {
        "id": "U0Zhv2jQeoo-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By  using the distance transform we can find basins in the center of each cell."
      ],
      "metadata": {
        "id": "zh4vWShjwLVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Computes the Distance Transform distance in the image\n",
        "distance = -ndi.distance_transform_edt(watershed_starting_mask)                       \n",
        "\n",
        "# Plotting the image as the 3d dimension figure.\n",
        "space= np.arange(0, distance.shape[0], 1)\n",
        "xx, yy = np.meshgrid(space,space)\n",
        "fig = plt.figure(figsize=(15,7))\n",
        "# Set up the axes for the first plot\n",
        "ax = fig.add_subplot(1, 2, 1)\n",
        "ax.imshow(distance,cmap='Spectral') # Reds_r\n",
        "# Set up the axes for the second plot\n",
        "ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n",
        "ax2.plot_surface(xx, yy , distance,  rstride=5, cstride=5, shade=False, cmap='Spectral')\n",
        "#ax2.view_init(30, 45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rl3Zuqwbo_ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#distance = -ndi.distance_transform_edt(watershed_starting_mask)                       \n",
        "random.choice(participants)"
      ],
      "metadata": {
        "id": "7jghcDuNX99N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JWMuqfO0nnE"
      },
      "source": [
        "# Apply watershed\n",
        "distance = ndi.distance_transform_edt(watershed_starting_mask)                       # Computes the Distance Transform distance in the image\n",
        "coords = peak_local_max(distance, min_distance=50, labels=watershed_starting_mask)   # Use the Distance transform image to find local maxima\n",
        "_,inds = np.unique(distance[coords[:,0],coords[:,1]],return_index=True)      # Make sure they are unique\n",
        "coords = coords[inds,:]                                                      # Selecting unique indexes\n",
        "mask = np.zeros(distance.shape, dtype=bool)                                  # Prealocating an array with zeros\n",
        "mask[tuple(coords.T)] = True                                                 # Make an image with 1's where local maxima are\n",
        "markers, _ = ndi.label(mask)                                                 # Unique values used as the desired labels\n",
        "\n",
        "# Using the watershed algorithm\n",
        "labels = watershed(-distance, markers, mask=watershed_starting_mask, watershed_line=True)  #Why do we need to use the negative of the distance matrix?\n",
        "\n",
        "# Plotting the results\n",
        "f,ax = plt.subplots(1,5, figsize=(15,7))\n",
        "ax[0].imshow(img, cmap='Spectral')\n",
        "ax[0].set_title('origninal')\n",
        "ax[1].imshow(watershed_starting_mask, cmap='Greys_r')\n",
        "ax[1].set_title('Mask')\n",
        "ax[2].imshow(ndi.distance_transform_edt(watershed_starting_mask), cmap='Greys')\n",
        "ax[2].set_title('Distance Transform')\n",
        "ax[3].imshow(ndi.distance_transform_edt(watershed_starting_mask), cmap='Greys')\n",
        "ax[3].scatter(coords[:,1],coords[:,0],c='r')\n",
        "ax[3].set_title('Local Maxima in Dist. Transform')\n",
        "ax[4].imshow(labels, cmap='Spectral')\n",
        "ax[4].set_title('Masks with Labels')\n",
        "f.tight_layout() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The concept of **Masks** and labels"
      ],
      "metadata": {
        "id": "VKLLoqyzwlCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.choice(participants)   "
      ],
      "metadata": {
        "id": "LpSRsz5BZ9rG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#np.unique(labels)\n",
        "#plt.imshow(labels==2)"
      ],
      "metadata": {
        "id": "QgEPYfcqnGgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Why do we need to use the negative of the distance matrix?\n",
        "#random.choice(participants)"
      ],
      "metadata": {
        "id": "BT1A0YVTzbpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#help(watershed)"
      ],
      "metadata": {
        "id": "Q8rt34BKqFoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qy5Eyw_MDs5N"
      },
      "source": [
        "# Machine Learning Methods\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Please notice that a complete tutorial on Machine Learning will be given on June 5 by Zach Fox.**"
      ],
      "metadata": {
        "id": "IBQyNhDd6L_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "In recent years, deep learning methods have rapidly improved the state of the art for cell segmentation methods. We will come back to the theory on this topic - for now, we will demonstrate a couple of ML-based tools that can be used to segment images. If you are keen to get started learning about how the popular U-Net model works, check out [this video](https://www.youtube.com/watch?v=azM57JuQpQI) and/or [this video](https://www.youtube.com/watch?v=4ZZjr6SFBV8).\n"
      ],
      "metadata": {
        "id": "vdBaFKmTPw0U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cellpose"
      ],
      "metadata": {
        "id": "qCWrJ0dkJg3w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The [CellPose](https://www.nature.com/articles/s41592-020-01018-x) algorithm uses a [U-Net approach](https://arxiv.org/pdf/1505.04597.pdf), but is a generalist algorithm that can work with a wide variety of cell types. Published in 2021.  ~ 360 citations."
      ],
      "metadata": {
        "id": "Bsmieh02P066"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src= https://github.com/MunskyGroup/uqbio2022/raw/master/files/files_image_processing/module_1_2/images/Slide9.png alt=\"drawing\" width=\"1200\"/>"
      ],
      "metadata": {
        "id": "3rVGFURFJi7w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of the biggest problems in single-cell segmentation is the limited number of images that are needed to traing a machine learning algorithm."
      ],
      "metadata": {
        "id": "4wBGaW6q214I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src= https://github.com/MunskyGroup/uqbio2022/raw/master/files/files_image_processing/module_1_2/images/Slide11.png alt=\"drawing\" width=\"1200\"/>"
      ],
      "metadata": {
        "id": "09v-glM7Jorc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Segmenting a complete cell using Cellpose"
      ],
      "metadata": {
        "id": "ao89kvM2KS7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Downloading test image\n",
        "\n",
        "# Hela Cells. Linda's Publication.\n",
        "urls = ['https://ndownloader.figshare.com/files/26751209']\n",
        "urllib.request.urlretrieve(urls[0], './image_cell.tif')\n",
        "figName = './image_cell.tif'\n",
        "image_complete = imread(figName) \n",
        "\n",
        "print('image shape: ', image_complete.shape)\n",
        "\n",
        "# Plotting each one of the 3 colors independently\n",
        "fig, ax = plt.subplots(1,3, figsize=(20, 7))\n",
        "ax[0].imshow(image_complete[0,:,:,0],cmap='Reds_r')\n",
        "ax[1].imshow(image_complete[0,:,:,1],cmap='Greens_r')\n",
        "ax[2].imshow(image_complete[0,:,:,2],cmap='Blues_r')\n",
        "ax[0].axis('off')\n",
        "ax[1].axis('off')\n",
        "ax[2].axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "iBmNsx7YLNFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing cellpose"
      ],
      "metadata": {
        "id": "CSKrmickLUH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "! pip install opencv-python-headless==4.7.0.72\n",
        "! pip install cellpose==2.0\n",
        "from cellpose import models\n",
        "from cellpose import plot"
      ],
      "metadata": {
        "id": "olIN6WbyKDkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img= image_complete[0,:,:,0]"
      ],
      "metadata": {
        "id": "v4LNS2GcH1cm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RUN CELLPOSE\n",
        "use_GPU = True # models.use_gpu()\n",
        "model = models.Cellpose(gpu=use_GPU, model_type='cyto') # model_type='cyto' or model_type='nuclei'\n",
        "masks  = model.eval(img, diameter=200, flow_threshold=0.4, channels=[0,0])[0]\n",
        "\n",
        "# Plotting each one of the 3 colors independently\n",
        "fig, ax = plt.subplots(1,2, figsize=(20, 7))\n",
        "ax[0].imshow(img,cmap='Greys_r')\n",
        "ax[1].imshow(masks,cmap='Spectral')\n",
        "ax[0].axis('off')\n",
        "ax[1].axis('off')\n",
        "plt.show()\n",
        "print('Values in mask: ', np.unique (masks))"
      ],
      "metadata": {
        "id": "KzFpTxTkKJw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#help(model.eval)"
      ],
      "metadata": {
        "id": "Lqo9hVc0Gn42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Segmenting nuclei and cytosol"
      ],
      "metadata": {
        "id": "5BX0P_YUKQjv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Downloading Fluorescence In Situ Hybridization (FISH) data\n",
        "# Downloading the image to Colab\n",
        "%%capture\n",
        "urls = ['https://github.com/MunskyGroup/FISH_Processing/raw/main/dataBases/example_data/ROI002_XY1620755646_Z00_T0_merged.tif']\n",
        "print('Downloading file...')\n",
        "urllib.request.urlretrieve(urls[0], './ROI001_XY1620755243_Z00_T0_merged.tif')\n",
        "figName = './ROI001_XY1620755243_Z00_T0_merged.tif'\n",
        "images_FISH = imread(figName) \n",
        "\n",
        "# The image has the following dimensions [Z,Y,X,C]\n",
        "print('The image has the following dimensions [Z,Y,X,C]: ' ,images_FISH.shape)\n",
        "\n",
        "# For segmentation, we will select the central  slice.\n",
        "image_to_segment= images_FISH[10,:,:,:]\n",
        "\n",
        "fig, ax = plt.subplots(1,3, figsize=(15, 8))\n",
        "ax[0].imshow(images_FISH[10,:,:,0],cmap='Spectral_r')\n",
        "ax[0].set(title='Ch0 - DAPI')\n",
        "ax[1].imshow(images_FISH[10,:,:,1],cmap='Spectral_r')\n",
        "ax[1].set(title= 'Ch1 - FISH vs MS2  reporter gene' )\n",
        "ax[2].imshow(images_FISH[10,:,:,2],cmap='Spectral_r')\n",
        "ax[2].set(title= 'Ch1 - FISH vs GAPDH' )\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JXv2BxIpPtrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Segmenting the nuclei\n",
        "img_nuc = images_FISH[10,:,:,0:2]\n",
        "print(img_nuc.shape)\n",
        "use_GPU = True\n",
        "model = models.Cellpose(gpu=use_GPU, model_type='nuclei') # model_type='cyto' or model_type='nuclei'\n",
        "masks_nuc = model.eval(img_nuc, diameter=100, flow_threshold=0.4, channels=[0,1], net_avg=True, augment=True)[0]\n",
        "print('number of detected cells: ', np.max(masks_nuc))\n",
        "plt.imshow(masks_nuc,cmap='Greys_r')\n",
        "plt.show()\n",
        "\n",
        "image_to_segment= images_FISH[10,:,:,:]\n",
        "\n",
        "fig, ax = plt.subplots(1,3, figsize=(15, 8))\n",
        "ax[0].imshow(images_FISH[10,:,:,0],cmap='Spectral_r')\n",
        "ax[0].set(title='Ch0 - DAPI')\n",
        "ax[1].imshow(images_FISH[10,:,:,1],cmap='Spectral_r')\n",
        "ax[1].set(title= 'Ch1 - FISH vs MS2  reporter gene' )\n",
        "ax[2].imshow(images_FISH[10,:,:,2],cmap='Spectral_r')\n",
        "ax[2].set(title= 'Ch1 - FISH vs GAPDH' )\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3AjZyaDzLtyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Segmenting the cytosol\n",
        "img_cyto = images_FISH[10,:,:,0:3]\n",
        "print(img_cyto.shape)\n",
        "use_GPU = True \n",
        "model = models.Cellpose(gpu=use_GPU, model_type='cyto2') # model_type='cyto', 'cyto2' or model_type='nuclei'\n",
        "masks_cyto, flows, styles, diams = model.eval(img_cyto, diameter=200, flow_threshold=0.4, channels=[0,2], net_avg=True, augment=True)\n",
        "plt.imshow(masks_cyto,cmap='Greys_r')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "h-khEZswLyj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculating the area of each cell in the image"
      ],
      "metadata": {
        "id": "JJ09qdWMieui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How to access to the pixels forming each cell\n",
        "random.choice(participants)"
      ],
      "metadata": {
        "id": "hdR0gOiZbiwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "number_detected_cells = np.max(masks_cyto)\n",
        "\n",
        "fig, ax = plt.subplots(1,number_detected_cells, figsize=(15, 8))\n",
        "for i in range (1,number_detected_cells+1):\n",
        "  selected_mask = masks_cyto==i\n",
        "  ax[i-1].imshow(selected_mask,cmap='Spectral_r')\n",
        "  ax[i-1].set(title='mask == ' + str(i) )\n",
        "  ax[i-1].axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "RW06XWcHsG46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_areas = []\n",
        "for i in range (1,number_detected_cells+1):\n",
        "  selected_mask = masks_cyto==i\n",
        "  area = np.sum(selected_mask)\n",
        "  list_areas.append(area)\n",
        "print(list_areas)"
      ],
      "metadata": {
        "id": "XCOQP1vzic1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# working with lists?\n",
        "random.choice(participants)"
      ],
      "metadata": {
        "id": "DA4pgk6fcEb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculating the mean intensity of each cell in the image"
      ],
      "metadata": {
        "id": "m-WmgV1eilhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# how to select the pixels forming a cell\n",
        "fig, ax = plt.subplots(1,3, figsize=(15, 8))\n",
        "ax[0].imshow(img_cyto[:,:,2])\n",
        "selected_cell_label = 4 #selecting specific cell\n",
        "selected_mask = masks_cyto == selected_cell_label  # Select other cell label\n",
        "ax[1].imshow(selected_mask)\n",
        "ax[2].imshow(selected_mask*img_cyto[:,:,2])\n",
        "ax[0].set(title='original image')\n",
        "ax[1].set(title='selected mask')\n",
        "ax[0].set(title='multiplication')\n",
        "ax[0].axis('off')\n",
        "ax[1].axis('off')\n",
        "ax[2].axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5SzIayBIuoA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ax[2].imshow(selected_mask*img_cyto[:,:,2])\n",
        "random.choice(participants)"
      ],
      "metadata": {
        "id": "OYgY7skrbVjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying the mask to original image\n",
        "list_mean_intensities = []\n",
        "for i in range (1,number_detected_cells+1):\n",
        "  selected_mask = masks_cyto==i\n",
        "  mean_intensity = np.mean(selected_mask*img_cyto[:,:,2])\n",
        "  list_mean_intensities.append(mean_intensity)\n",
        "list_mean_intensities"
      ],
      "metadata": {
        "id": "A-rtgJN5iqp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spot detection\n",
        "\n",
        "___"
      ],
      "metadata": {
        "id": "hFadrXoT-_1E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spot detection: thresholding -> binarization -> labeling"
      ],
      "metadata": {
        "id": "OyqCsXTIbj8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting the color channel with RNA spots\n",
        "img_spots = images_FISH[10,:,:,1]\n",
        "\n",
        "fig, ax = plt.subplots(1,2, figsize=(12, 6))\n",
        "ax[0].imshow(img_spots,cmap='Greys_r')\n",
        "ax[0].set(title='')\n",
        "ax[1].hist(img_spots.flatten(),bins=50)\n",
        "ax[1].set(title= 'Intensity' )\n",
        "plt.show()\n",
        "print('intensity range: ', np.min(img_spots), np.max(img_spots))"
      ],
      "metadata": {
        "id": "QNb3gFYIOgpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 1800 "
      ],
      "metadata": {
        "id": "l2IhxxjPOF64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Image Threshold selection\n",
        "img_spots_binary = img_spots.copy() \n",
        "img_spots_binary[img_spots_binary>=threshold] = threshold # Making spots above the threshold equal to the threshold value.\n",
        "img_spots_binary[img_spots_binary<threshold] = 0 # Making spots below the threshold equal to 0.\n",
        "\n",
        "# Image binarization\n",
        "img_spots_binary[img_spots_binary!=0] = 1 # Binarization\n",
        "print('Range values in binarized image: ', np.min(img_spots_binary), np.max(img_spots_binary))\n",
        "\n",
        "# Labeling. Joining pixels in \"particles\" \n",
        "contours = measure.find_contours(img_spots_binary, 0.5)\n",
        "\n",
        "# plotting image\n",
        "fig, ax = plt.subplots(1,3, figsize=(12, 6))\n",
        "ax[0].imshow(img_spots,cmap='Greys_r')\n",
        "ax[0].set(title='original image')\n",
        "ax[1].imshow(img_spots_binary,cmap='Greys_r')\n",
        "ax[1].set(title= 'Binary image' )\n",
        "ax[2].imshow(img_spots_binary, cmap=plt.cm.gray)\n",
        "for contour in contours:\n",
        "    ax[2].plot(contour[:, 1], contour[:, 0], linewidth=2)\n",
        "ax[2].set(title= str(len(contours))+' Detected particles' )\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gAxpA9KZO_Tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src= https://github.com/MunskyGroup/uqbio2022/raw/master/files/files_image_processing/module_1_3/images/Slide8.png alt=\"drawing\" width=\"1200\"/>"
      ],
      "metadata": {
        "id": "_NHgutaJgdO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing libraries\n",
        "%%capture\n",
        "! pip install trackpy \n",
        "import trackpy as tp # Library for particle tracking"
      ],
      "metadata": {
        "id": "lx6ax9DaNG8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This section generates an histograme with the intensity of the detected particles in the image.\n",
        "particle_size = 3 # according to the documentation must be an odd number 3,5,7,9 etc.\n",
        "minimal_intensity_for_selection = 0 # minimal intensity to detect a particle.\n",
        "# \"spots_detected_dataframe\" is a pandas data freame that contains the infomation about the detected spots\n",
        "spots_detected_dataframe = tp.locate(img_spots, diameter=particle_size, minmass=minimal_intensity_for_selection) \n"
      ],
      "metadata": {
        "id": "nYfSgoKdVGIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,1, figsize=(5, 5))\n",
        "ax.hist(spots_detected_dataframe['mass'], bins=100, color = \"orangered\", ec=\"orangered\")\n",
        "ax.set(xlabel='mass', ylabel='count')\n",
        "ax.set_ylim([0,1000])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UHW910TvWq_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(5,10))\n",
        "spots_detected_dataframe = tp.locate(img_spots,diameter=3, minmass=150) # \"spots_detected_dataframe\" is a pandas data freame that contains the infomation about the detected spots\n",
        "tp.annotate(spots_detected_dataframe,img_spots,plot_style={'markersize': 1})  # tp.anotate is a trackpy function that displays the image with the detected spots  \n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SN_UsA6HV1d6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(spots_detected_dataframe.head())"
      ],
      "metadata": {
        "id": "1rsf11lpc22Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#help(tp.locate)"
      ],
      "metadata": {
        "id": "xMopHrGxdnFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extracting information from a Pandas data frame using conditionals"
      ],
      "metadata": {
        "id": "tdw009NDdMfq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Showing information for particle with mass larger than > \n",
        "min_mass = 200\n",
        "spots_detected_dataframe.loc[spots_detected_dataframe['mass']>min_mass ]"
      ],
      "metadata": {
        "id": "5nX98BYFc5d_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Showing information for particles smaller than\n",
        "min_size = 0.55\n",
        "spots_detected_dataframe.loc[spots_detected_dataframe['size']<min_size]"
      ],
      "metadata": {
        "id": "dAI-TpEWdCxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting the y values for all particles\n",
        "spots_detected_dataframe.y.values[0:10]"
      ],
      "metadata": {
        "id": "0sp8HykLdC9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional section that saves the particles trajectories and intensities as a CSV file\n",
        "spots_detected_dataframe.to_csv(r'./detected_spots.csv', index = False)"
      ],
      "metadata": {
        "id": "H3aQIAnGhWiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def spots_in_mask(df,masks):\n",
        "    # extracting the contours in the image\n",
        "    coords = np.array([df.y, df.x]).T # These are the points detected by trackpy\n",
        "    coords_int = np.round(coords).astype(int)  # or np.floor, depends\n",
        "    values_at_coords = masks[tuple(coords_int.T)] # If 1 the value is in the mask\n",
        "    df['In Mask']=values_at_coords # Check if pts are on/in polygon mask  \n",
        "    return df "
      ],
      "metadata": {
        "id": "Gyv2iZX_NHLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe_spots_in_nuc = spots_in_mask(df=spots_detected_dataframe, masks= masks_nuc) "
      ],
      "metadata": {
        "id": "OMehkHJ0UmJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe_spots_in_nuc"
      ],
      "metadata": {
        "id": "88ZjUxIQUmOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting only the spots located on a given cell\n",
        "selected_cell = 1 # Test cell 2\n",
        "dataframe_spots_cell_N = dataframe_spots_in_nuc[dataframe_spots_in_nuc['In Mask']==selected_cell]"
      ],
      "metadata": {
        "id": "dvwOcoHbfgPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe_spots_cell_N"
      ],
      "metadata": {
        "id": "QuUg6VFVUmTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Spot detection using [Big-FISH](https://github.com/fish-quant/big-fish)\n",
        "- Spot detection using [FISH Processing](https://colab.research.google.com/drive/1CQx4e5MQ0ZsZSQgqtLzVVh53dAg4uaQj?usp=sharing)"
      ],
      "metadata": {
        "id": "mQ5RPKXRUJ69"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Advanced segmentation"
      ],
      "metadata": {
        "id": "a0ZfcN5-pxDq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Downloading a test image\n",
        "\n",
        "# Downloading a test image\n",
        "urls = ['https://ndownloader.figshare.com/files/26751209']\n",
        "print('Downloading file...')\n",
        "figName = './image_cell.tif'\n",
        "urllib.request.urlretrieve(urls[0], figName)\n",
        "# Loading figure to the notebook\n",
        "imgs_2 = imread(figName) \n",
        "print('File is downloaded and accessible in: ... /contents/image_cell.tif ')\n",
        "print(imgs_2.shape)"
      ],
      "metadata": {
        "id": "wqxVMJFs5nkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate a mask for every frame (time point) in the video."
      ],
      "metadata": {
        "id": "CWELKV1aMwPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Need a mask for the cell -- tels us which pixels are inside the cell.\n",
        "use_GPU = True # models.use_gpu()\n",
        "model = models.Cellpose(gpu=use_GPU, model_type='cyto') # model_type='cyto' or model_type='nuclei'\n",
        "# Running the model for all  frames\n",
        "masks_for_all_frames, _, _, _ = model.eval(imgs_2[:,:,:,:], diameter=200, min_size=1000, channels=[0,0])\n",
        "# Notice that the output is a tensor with  shape [T,Y,X]\n",
        "print(masks_for_all_frames.shape)\n",
        "\n",
        "# Plotting the  masks founds for every frame.\n",
        "number_frames= imgs_2.shape[0]\n",
        "fig, ax = plt.subplots(nrows=1,ncols=number_frames, figsize=(20, 5))\n",
        "for i in range(number_frames):\n",
        "  ax[i].imshow(masks_for_all_frames[i,:,:])\n",
        "  ax[i].axis('off')"
      ],
      "metadata": {
        "id": "7EiYsCytMxuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Downloading a FISH image\n",
        "# Downloading a FISH image\n",
        "urls = ['https://github.com/MunskyGroup/FISH_Processing/raw/main/dataBases/example_data/ROI002_XY1620755646_Z00_T0_merged.tif']\n",
        "print('Downloading file...')\n",
        "urllib.request.urlretrieve(urls[0], './ROI001_XY1620755243_Z00_T0_merged.tif')\n",
        "figName = './ROI001_XY1620755243_Z00_T0_merged.tif'\n",
        "images_FISH = imread(figName) \n",
        "print('File Downloaded!')"
      ],
      "metadata": {
        "id": "ilpAxHrW6bQD",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using a maximum projection in Z, calculate the mask for the nuclei and cytosol in the FISH image."
      ],
      "metadata": {
        "id": "khCPDZOmNWxe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add your code with your response here:\n",
        "print('The shape of the FISH image is : ', images_FISH.shape)  #[Z,Y,X,C]\n",
        "\n",
        "# Inspecting the image to determine the channel with nucleus and cytosol\n",
        "fig, ax = plt.subplots(1,3, figsize=(20, 10))\n",
        "ax[0].imshow(images_FISH[10,:,:,0],cmap='Spectral_r')\n",
        "ax[0].set(title='Ch0 - DAPI')\n",
        "ax[1].imshow(images_FISH[10,:,:,1],cmap='Spectral_r')\n",
        "ax[1].set(title= 'Ch1 - FISH vs MS2  reporter gene' )\n",
        "ax[2].imshow(images_FISH[10,:,:,2],cmap='Spectral_r')\n",
        "ax[2].set(title= 'Ch1 - FISH vs GAPDH' )\n",
        "plt.show()\n",
        "\n",
        "# From the image we could determine \n",
        "channel_nucleus = 0\n",
        "channel_cytosol = 2\n",
        "\n",
        "# Creating  maximum projections for channel 0 and channel 2.\n",
        "max_z_projection_nucleus = np.max(images_FISH[:,:,:,channel_nucleus], axis=0)\n",
        "max_z_projection_cytosol = np.max(images_FISH[:,:,:,channel_cytosol], axis=0)\n",
        "\n",
        "# Notice that this projection reduced the dimenssions to\n",
        "print('Dimensions in tensor with nucleus image : ' , max_z_projection_nucleus.shape)\n",
        "print('Dimensions in tensor with cytosol image : ' , max_z_projection_cytosol.shape)\n",
        "\n",
        "# Using cellpose\n",
        "\n",
        "# NUCLEUS\n",
        "model = models.Cellpose(gpu=use_GPU, model_type='nuclei') # model_type='cyto' or model_type='nuclei'\n",
        "masks_nuc, _, _, _ = model.eval(max_z_projection_nucleus, diameter=100, flow_threshold=None,  min_size=1000,net_avg=True, augment=True)\n",
        "plt.title('Nucleus segmentation')\n",
        "plt.imshow(masks_nuc,cmap='Greys_r')\n",
        "plt.show()\n",
        "\n",
        "# CYTOSOL\n",
        "model = models.Cellpose(gpu=use_GPU, model_type='cyto2') # model_type='cyto', 'cyto2' or model_type='nuclei'\n",
        "masks_cyto, _, _, _ = model.eval(max_z_projection_cytosol, diameter=200, flow_threshold=None,  min_size=1000,net_avg=True, augment=True)\n",
        "plt.imshow(masks_cyto,cmap='Greys_r')\n",
        "plt.title('Cytosol segmentation')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "T4U5aOhONW62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate the center of mass of each cell in the FISH image."
      ],
      "metadata": {
        "id": "LUcR6v6TN14n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add your code with your response here:\n",
        "number_masks = np.max(masks_cyto)\n",
        "list_center_mass =[]\n",
        "print('number cellls in image : ', number_masks)\n",
        "for i in range (1,number_masks+1):\n",
        "  # Calculaitng  the center of mass for a selected cell.\n",
        "  selected_mask_cyto = np.where(masks_cyto==i,1,0) # Selecting only one mask.    \n",
        "  y_indexes = np.nonzero(selected_mask_cyto)[0] # Detecting the indexes for all x axis\n",
        "  x_indexes = np.nonzero(selected_mask_cyto)[1] # Detecting the indexes for all y axis\n",
        "  center_mass_x = int ( np.sum(x_indexes) / np.sum(selected_mask_cyto) )\n",
        "  center_mass_y = int( np.sum(y_indexes) / np.sum(selected_mask_cyto) )\n",
        "  list_center_mass.append((center_mass_x,center_mass_y ) )\n",
        "  del y_indexes, x_indexes, selected_mask_cyto, center_mass_x, center_mass_y\n",
        "\n",
        "# Plotting the selected cell and its center of mass\n",
        "plt.figure(figsize=(7,7))\n",
        "plt.imshow(masks_cyto,cmap='Greys_r')\n",
        "for i in range(len(list_center_mass)):\n",
        "  plt.scatter(list_center_mass[i][0],list_center_mass[i][1],s=30)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9RbANiSZOCRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugjw-hs2yBYY"
      },
      "source": [
        "# References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzGe4WvLx8sB"
      },
      "source": [
        "*  Image downloaded from https://figshare.com from publication: \"Forero-Quintero, Linda, William Raymond, Tetsuya Handa, Matthew Saxton, Tatsuya Morisaki, Hiroshi Kimura, Edouard Bertrand, Brian Munsky, and Timothy Stasevich. \"Live-cell imaging reveals the spatiotemporal organization of endogenous RNA polymerase II phosphorylation at a single gene.\" (2020).\"\n",
        "\n",
        "* \"Fox, Z.R., Fletcher, S., Fraisse, A., Aditya, C., Sosa-Carrillo, S., Gilles, S., Bertaux, F., Ruess, J. and Batt, G., 2021. MicroMator: Open and Flexible Software for Reactive Microscopy. bioRxiv. (2021)\""
      ]
    }
  ]
}